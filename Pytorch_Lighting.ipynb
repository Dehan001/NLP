{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30a19be5431b4a05b799ae541f35257a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70c1ca1f5e4e4c72a0a96c598f0cf55a",
              "IPY_MODEL_94fb1e96ce9741a5b2b80896899572b4",
              "IPY_MODEL_4c6a273e7081456f8c47ef87a4c9da53"
            ],
            "layout": "IPY_MODEL_ff9857f5e015406081183a31857e01c2"
          }
        },
        "70c1ca1f5e4e4c72a0a96c598f0cf55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c75d59500d3409083ca15458618ad01",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b3b169aa724ecf9991a48e21d35e05",
            "value": "Sanity Checking: "
          }
        },
        "94fb1e96ce9741a5b2b80896899572b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee84cd77dfc14497bc97234fe7cf4d6c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6efe42ce7b6c4ae0b15caf944449ae18",
            "value": 0
          }
        },
        "4c6a273e7081456f8c47ef87a4c9da53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bf6d30b55743c9b9d9ccaa3c30c0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_61c86553f9dc479db4cddbace94ee354",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "ff9857f5e015406081183a31857e01c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8c75d59500d3409083ca15458618ad01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b3b169aa724ecf9991a48e21d35e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee84cd77dfc14497bc97234fe7cf4d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efe42ce7b6c4ae0b15caf944449ae18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44bf6d30b55743c9b9d9ccaa3c30c0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c86553f9dc479db4cddbace94ee354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "30a19be5431b4a05b799ae541f35257a",
            "70c1ca1f5e4e4c72a0a96c598f0cf55a",
            "94fb1e96ce9741a5b2b80896899572b4",
            "4c6a273e7081456f8c47ef87a4c9da53",
            "ff9857f5e015406081183a31857e01c2",
            "8c75d59500d3409083ca15458618ad01",
            "a5b3b169aa724ecf9991a48e21d35e05",
            "ee84cd77dfc14497bc97234fe7cf4d6c",
            "6efe42ce7b6c4ae0b15caf944449ae18",
            "44bf6d30b55743c9b9d9ccaa3c30c0f1",
            "61c86553f9dc479db4cddbace94ee354"
          ]
        },
        "id": "mgqS_3ba7gvP",
        "outputId": "cff14353-e7f7-49b3-fdb4-4ced0536a35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38321, 2)\n",
            "30656 3832 3832\n",
            "Requirement already satisfied: labml-nn in /usr/local/lib/python3.10/dist-packages (0.4.133)\n",
            "Requirement already satisfied: labml>=0.4.158 in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.4.162)\n",
            "Requirement already satisfied: labml-helpers>=0.4.89 in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.4.89)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from labml-nn) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.15.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.15.2+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from labml-nn) (1.22.4)\n",
            "Requirement already satisfied: fairscale in /usr/local/lib/python3.10/dist-packages (from labml-nn) (0.4.13)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (from labml>=0.4.158->labml-nn) (3.1.31)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from labml>=0.4.158->labml-nn) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->labml-nn) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->labml-nn) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->labml-nn) (16.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext->labml-nn) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext->labml-nn) (2.27.1)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext->labml-nn) (0.6.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext->labml-nn) (1.26.16)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->labml-nn) (8.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython->labml>=0.4.158->labml-nn) (4.0.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->labml-nn) (2.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->labml-nn) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->labml-nn) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext->labml-nn) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->labml-nn) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython->labml>=0.4.158->labml-nn) (5.0.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.6.3)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | model     | Transformer      | 432 K \n",
            "1 | criterion | CrossEntropyLoss | 0     \n",
            "-----------------------------------------------\n",
            "432 K     Trainable params\n",
            "0         Non-trainable params\n",
            "432 K     Total params\n",
            "1.730     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30a19be5431b4a05b799ae541f35257a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7dbd61a06412>\u001b[0m in \u001b[0;36m<cell line: 418>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         )\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0;31m# consume the batch we just fetched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m_fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "class Textpreprocessing:\n",
        "  def __init__(self,text):\n",
        "    self.text=text\n",
        "\n",
        "  def words(self,str1):\n",
        "    tokens=str1.split()[:4]\n",
        "    str2=''\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "      if i==0:\n",
        "        str2+=tokens[i]\n",
        "      else:\n",
        "        str2=str2+\" \"+tokens[i]\n",
        "\n",
        "    return str2\n",
        "\n",
        "\n",
        "\n",
        "  def stopword_remove(self,str1):\n",
        "    str1=str1.lower()\n",
        "    tokens=str1.split()\n",
        "    str2=\"\"\n",
        "    stop_words=stopwords.words('english')\n",
        "    for word in tokens:\n",
        "      if not word in stop_words:\n",
        "        str2+=word+' '\n",
        "    return str2\n",
        "\n",
        "  def url_remove(self,str1):\n",
        "    str1=re.sub(r'http\\S+', '', str1)\n",
        "    str1=re.sub(r'www\\S+', '', str1)\n",
        "    return str1\n",
        "\n",
        "  def clean_punctuation(self,str1):\n",
        "    str1=re.sub(r'[^\\w\\s]','',str1)\n",
        "    return str1\n",
        "\n",
        "  def cleaningdigits(self,str1):\n",
        "    str1=re.sub(r'[\\d+]','',str1)\n",
        "    return str1\n",
        "\n",
        "  def lemmatization(self,str1):\n",
        "    lemma=WordNetLemmatizer()\n",
        "    str2=''\n",
        "    tokens=str1.split()\n",
        "    for word in tokens:\n",
        "      store=lemma.lemmatize(word)\n",
        "      str2+=store+' '\n",
        "    return str2\n",
        "\n",
        "  def preprocess(self):\n",
        "    self.text=self.text.apply(self.words)\n",
        "    self.text=self.text.apply(self.stopword_remove)\n",
        "    self.text=self.text.apply(self.url_remove)\n",
        "    self.text=self.text.apply(self.clean_punctuation)\n",
        "    self.text=self.text.apply(self.cleaningdigits)\n",
        "    self.text=self.text.apply(self.lemmatization)\n",
        "\n",
        "    return self.text\n",
        "\n",
        "\n",
        "url='https://drive.google.com/file/d/12bhIJ9uIO4npZzq9Y4xt15WvZme6p9zn/view?usp=share_link'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "\n",
        "\n",
        "df.drop('parent_id',inplace=True,axis=1)\n",
        "df.drop('length',inplace=True,axis=1)\n",
        "df.drop('size_range',inplace=True,axis=1)\n",
        "df=df.drop_duplicates()\n",
        "\n",
        "df=df[df['text'].notnull()]\n",
        "df=df[df['topic'].notnull()]\n",
        "\n",
        "\n",
        "print(df.shape)\n",
        "\n",
        "text_preprocess=Textpreprocessing(df['text'])\n",
        "df['text']=text_preprocess.preprocess()\n",
        "document_size=len(df)\n",
        "\n",
        "df.groupby(['topic']).size().plot.bar()\n",
        "df['topic']=df['topic'].astype('str')\n",
        "\n",
        "df.groupby(['topic']).size()\n",
        "\n",
        "df.drop(df.loc[df['topic']=='48'].index, inplace=True)\n",
        "\n",
        "df.groupby(['topic']).size().plot.bar()\n",
        "\n",
        "#change glove overall\n",
        "new_model=gensim.downloader.load('glove-twitter-25')\n",
        "new_model.most_similar(\"bad\")\n",
        "wv_size=len(new_model['bad'])\n",
        "\n",
        "\n",
        "def create_word2vec_for_setence(text,max_word):\n",
        "\n",
        "  results  = np.zeros(shape = (max_word,wv_size))\n",
        "  #for i, documents in enumerate(text):\n",
        "  for j, considered_word in list(enumerate(text.split())):\n",
        "    try:\n",
        "      results[j, :] = new_model[considered_word]\n",
        "    except:\n",
        "      results[j,:]=np.zeros((wv_size))\n",
        "  return torch.tensor(results,dtype=torch.float32)\n",
        "\n",
        "\n",
        "labels = {'movies':0,\n",
        "          'news':1,\n",
        "          'nfl':2,\n",
        "          'pcmasterrace':3,\n",
        "          'relationships':4\n",
        "          }\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  def __init__(self,df):\n",
        "\n",
        "    self.labels=[labels[label] for label in df['topic']]\n",
        "    self.texts=[create_word2vec_for_setence(text,512) for text in df['text']]\n",
        "\n",
        "\n",
        "\n",
        "  def classes(self):\n",
        "      return self.labels\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "  def get_batch_labels(self, idx):\n",
        "      # Fetch a batch of labels\n",
        "      return np.array(self.labels[idx])\n",
        "\n",
        "  def get_batch_texts(self, idx):\n",
        "      # Fetch a batch of inputs\n",
        "      return self.texts[idx]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      batch_texts = self.get_batch_texts(idx)\n",
        "      batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "      return batch_texts, batch_y\n",
        "\n",
        "\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))\n",
        "\n",
        "\n",
        "!pip install labml-nn\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from labml.logger import inspect\n",
        "from labml_nn.transformers.mha import MultiHeadAttention\n",
        "\n",
        "def shift_right(x: torch.Tensor):\n",
        "  zero_pad = x.new_zeros(x.shape[0], 1, *x.shape[2:])\n",
        "  x_padded = torch.cat([x, zero_pad], dim=1)\n",
        "  x_padded = x_padded.view(x.shape[1] + 1, x.shape[0], *x.shape[2:])\n",
        "  x = x_padded[:-1].view_as(x)\n",
        "  return x\n",
        "\n",
        "class RelativeMultiHeadAttention(MultiHeadAttention):\n",
        "  def __init__(self, heads: int, d_model: int, dropout_prob: float = 0.1):\n",
        "    super().__init__(heads, d_model, dropout_prob, bias=False)\n",
        "    self.P = 2 ** 12\n",
        "    self.key_pos_embeddings = nn.Parameter(torch.zeros((self.P * 2, heads, self.d_k)), requires_grad=True)\n",
        "    self.key_pos_bias = nn.Parameter(torch.zeros((self.P * 2, heads)), requires_grad=True)\n",
        "    self.query_pos_bias = nn.Parameter(torch.zeros((heads, self.d_k)), requires_grad=True)\n",
        "  def get_scores(self, query: torch.Tensor, key: torch.Tensor):\n",
        "    key_pos_emb = self.key_pos_embeddings[self.P - key.shape[0]:self.P + query.shape[0]]\n",
        "    key_pos_bias = self.key_pos_bias[self.P - key.shape[0]:self.P + query.shape[0]]\n",
        "    query_pos_bias = self.query_pos_bias[None, None, :, :]\n",
        "    ac = torch.einsum('ibhd,jbhd->ijbh', query + query_pos_bias, key)\n",
        "    b = torch.einsum('ibhd,jhd->ijbh', query, key_pos_emb)\n",
        "    d = key_pos_bias[None, :, None, :]\n",
        "    bd = shift_right(b + d)\n",
        "    bd = bd[:, -key.shape[0]:]\n",
        "    return ac + bd\n",
        "  def _test_shift_right():\n",
        "    def _test_shift_right():\n",
        "      x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "      inspect(x)\n",
        "      inspect(shift_right(x))\n",
        "      x = torch.arange(1, 6)[None, :, None, None].repeat(5, 1, 1, 1)\n",
        "      inspect(x[:, :, 0, 0])\n",
        "      inspect(shift_right(x)[:, :, 0, 0])\n",
        "      x = torch.arange(1, 6)[None, :, None, None].repeat(3, 1, 1, 1)\n",
        "      inspect(x[:, :, 0, 0])\n",
        "      inspect(shift_right(x)[:, :, 0, 0])\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "\n",
        "from labml_helpers.module import Module\n",
        "\n",
        "\n",
        "class FeedForward(Module):\n",
        "    \"\"\"\n",
        "    ## FFN module\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model: int, d_ff: int,\n",
        "                 dropout: float = 0.1,\n",
        "                 activation=nn.ReLU(),\n",
        "                 is_gated: bool = False,\n",
        "                 bias1: bool = True,\n",
        "                 bias2: bool = True,\n",
        "                 bias_gate: bool = True):\n",
        "        \"\"\"\n",
        "        * `d_model` is the number of features in a token embedding\n",
        "        * `d_ff` is the number of features in the hidden layer of the FFN\n",
        "        * `dropout` is dropout probability for the hidden layer\n",
        "        * `is_gated` specifies whether the hidden layer is gated\n",
        "        * `bias1` specified whether the first fully connected layer should have a learnable bias\n",
        "        * `bias2` specified whether the second fully connected layer should have a learnable bias\n",
        "        * `bias_gate` specified whether the fully connected layer for the gate should have a learnable bias\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Layer one parameterized by weight $W_1$ and bias $b_1$\n",
        "        self.layer1 = nn.Linear(d_model, d_ff, bias=bias1)\n",
        "        # Layer one parameterized by weight $W_1$ and bias $b_1$\n",
        "        self.layer2 = nn.Linear(d_ff, d_model, bias=bias2)\n",
        "        # Hidden layer dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Activation function $f$\n",
        "        self.activation = activation\n",
        "        # Whether there is a gate\n",
        "        self.is_gated = is_gated\n",
        "        if is_gated:\n",
        "            # If there is a gate the linear layer to transform inputs to\n",
        "            # be multiplied by the gate, parameterized by weight $V$ and bias $c$\n",
        "            self.linear_v = nn.Linear(d_model, d_ff, bias=bias_gate)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        # $f(x W_1 + b_1)$\n",
        "        g = self.activation(self.layer1(x))\n",
        "        # If gated, $f(x W_1 + b_1) \\otimes (x V + b) $\n",
        "        if self.is_gated:\n",
        "            x = g * self.linear_v(x)\n",
        "        # Otherwise\n",
        "        else:\n",
        "            x = g\n",
        "        # Apply dropout\n",
        "        x = self.dropout(x)\n",
        "        # $(f(x W_1 + b_1) \\otimes (x V + b)) W_2 + b_2$ or $f(x W_1 + b_1) W_2 + b_2$\n",
        "        # depending on whether it is gated\n",
        "        return self.layer2(x)\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from labml_helpers.module import Module\n",
        "from labml_nn.utils import clone_module_list\n",
        "\n",
        "\n",
        "class TransformerXLLayer(Module):\n",
        "  def __init__(self, *,d_model: int,self_attn: RelativeMultiHeadAttention,feed_forward: FeedForward,dropout_prob: float):\n",
        "    super().__init__()\n",
        "    self.size = d_model\n",
        "    self.self_attn = self_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.norm_self_attn = nn.LayerNorm([d_model])\n",
        "    self.norm_ff = nn.LayerNorm([d_model])\n",
        "  def forward(self, *,x: torch.Tensor,mem: Optional[torch.Tensor],mask: torch.Tensor):\n",
        "    z = self.norm_self_attn(x)\n",
        "    if mem is not None:\n",
        "      mem = self.norm_self_attn(mem)\n",
        "      m_z = torch.cat((mem, z), dim=0)\n",
        "    else:\n",
        "      m_z = z\n",
        "    self_attn = self.self_attn(query=z, key=m_z, value=m_z, mask=mask)\n",
        "    x = x + self.dropout(self_attn)\n",
        "    z = self.norm_ff(x)\n",
        "    ff = self.feed_forward(z)\n",
        "    x = x + self.dropout(ff)\n",
        "    return x\n",
        "\n",
        "class TransformerXL(Module):\n",
        "  def __init__(self, layer: TransformerXLLayer, n_layers: int):\n",
        "    super().__init__()\n",
        "    self.layers = clone_module_list(layer, n_layers)\n",
        "    self.norm = nn.LayerNorm([layer.size])\n",
        "  def forward(self, x: torch.Tensor, mem: List[torch.Tensor], mask: torch.Tensor):\n",
        "    new_mem = []\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      new_mem.append(x.detach())\n",
        "      m = mem[i] if mem else None\n",
        "      x = layer(x=x, mem=m, mask=mask)\n",
        "    return self.norm(x), new_mem\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dropout=0.9, input_dim=25, hidden_dim=10):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(input_dim, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Initialize Transformer-XL\n",
        "        d_model = input_dim  # Set the model dimensionality to the input dimension\n",
        "        self.layer = TransformerXLLayer(\n",
        "            d_model=d_model,\n",
        "            self_attn=RelativeMultiHeadAttention(d_model=d_model,heads=1),\n",
        "            feed_forward=FeedForward(d_model=d_model, d_ff=hidden_dim),\n",
        "            dropout_prob=dropout\n",
        "        )\n",
        "        self.transformer_xl = TransformerXL(layer=self.layer, n_layers=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pooled_output = x\n",
        "        #mean_pooled_output = torch.mean(pooled_output, dim=1)\n",
        "        #dropout_output = self.dropout(mean_pooled_output)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "\n",
        "        # Apply Transformer-XL\n",
        "        mem = []  # Initialize an empty memory list\n",
        "        mask = None  # You can define the mask based on your specific requirements\n",
        "        transformer_output, mem = self.transformer_xl(dropout_output, mem, mask)\n",
        "        mean_transformer_output = torch.mean(transformer_output, dim=1)\n",
        "        linear_output = self.linear(mean_transformer_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "class TextClassificationModel(pl.LightningModule):\n",
        "    def __init__(self, input_dim, hidden_dim, learning_rate):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Define your model architecture\n",
        "        self.model = Transformer(dropout=0.9, input_dim=input_dim, hidden_dim=hidden_dim)\n",
        "\n",
        "        # Define your loss function\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self.forward(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self.forward(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self.forward(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        self.log('test_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "# Prepare the data\n",
        "train_loader = torch.utils.data.DataLoader(df_train, batch_size=128, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(df_val, batch_size=128)\n",
        "test_loader = torch.utils.data.DataLoader(df_test,batch_size=128)\n",
        "# Initialize the Lightning module\n",
        "model = TextClassificationModel(input_dim=25, hidden_dim=10, learning_rate=0.001)\n",
        "\n",
        "# Initialize the Lightning Trainer\n",
        "trainer = pl.Trainer(gpus=-1,auto_select_gpus=True, max_epochs=10, progress_bar_refresh_rate=20)\n",
        "\n",
        "# Train the model\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "trainer.test(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EQhrNb_tAcoS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}