{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4nAMn9UpxW",
        "outputId": "3633c6d0-a5ff-41e8-892d-3b46866cc3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading pretrained model"
      ],
      "metadata": {
        "id": "S2E88tlj_oUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kye0hU19FktY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14afd2aa-e72d-413b-fe91-92a2de0af8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining text preprocessing class"
      ],
      "metadata": {
        "id": "DWzMpWB__r4P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTud1ux9aJhO"
      },
      "outputs": [],
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.punctuations = set(string.punctuation)\n",
        "\n",
        "    def process_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        text = ''.join(char for char in text if char not in self.punctuations)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        text = ' '.join(tokens)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def process_column(self, df, column_name):\n",
        "        df[column_name] = df[column_name].apply(self.process_text)\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading dataset"
      ],
      "metadata": {
        "id": "10VPQYcj_zwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRJdLUl7aKf9",
        "outputId": "b63da320-83b8-4f60-d089-daa3489bd9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('restuarents.csv', encoding='ISO-8859-1')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying text preprocessor"
      ],
      "metadata": {
        "id": "P6F9zztm_2P9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOC1ZmccaNVb",
        "outputId": "fd02e8b0-5a60-40cb-82d5-9d73e4ff869a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0                                    wow loved place      1\n",
            "1                                         crust good      0\n",
            "2                                tasty texture nasty      0\n",
            "3  stopped late may bank holiday rick steve recom...      1\n",
            "4                        selection menu great prices      1\n"
          ]
        }
      ],
      "source": [
        "preprocessor = TextPreprocessor()\n",
        "df = preprocessor.process_column(data, 'text')\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function for getting w2v representations"
      ],
      "metadata": {
        "id": "zcpGRaTR_76u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMNVwYkiaPtN"
      },
      "outputs": [],
      "source": [
        "def w2v(sentence):\n",
        "    tokenized_data = sentence.split()\n",
        "    n_tokens = len(tokenized_data)\n",
        "    if n_tokens >= 10:\n",
        "        tokenized_data = tokenized_data[:10]\n",
        "    else:\n",
        "        pad_length = 10 - n_tokens\n",
        "        tokenized_data += [\"<EOS>\"] * pad_length\n",
        "\n",
        "    vectors = []\n",
        "    for token in tokenized_data:\n",
        "        if token in w2v_model:\n",
        "            vec = w2v_model[token]\n",
        "        else:\n",
        "            vec = np.zeros(w2v_model.vector_size)\n",
        "        vectors.append(vec)\n",
        "\n",
        "    tensor = torch.stack([torch.tensor(vec, dtype=torch.float32) for vec in vectors])\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing w2v function"
      ],
      "metadata": {
        "id": "qtKf4YNaAA0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQPpU77zaUGj",
        "outputId": "4f6abcb6-2c48-4217-de0f-0bd0025f3e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 300])\n",
            "torch.Size([10, 300])\n",
            "torch.Size([10, 300])\n",
            "torch.Size([10, 300])\n"
          ]
        }
      ],
      "source": [
        "t = w2v(\"I am a good student\")\n",
        "print(t.shape)\n",
        "\n",
        "g = w2v(\"Hey are you going to the zoo tomorrow morning with me and my friends\")\n",
        "print(g.shape)\n",
        "\n",
        "y = w2v(\"you are a fool\")\n",
        "\n",
        "f =w2v(\"I quit\")\n",
        "print(y.shape)\n",
        "print(f.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Datasethelper child class"
      ],
      "metadata": {
        "id": "o-4NgktTAEai"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4hM54fGaWqG"
      },
      "outputs": [],
      "source": [
        "class Datasethelper(Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.data = df['text'].values\n",
        "    self.labels = df['label'].values\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    text = self.data[index]\n",
        "    label = self.labels[index]\n",
        "    w2v_data = w2v(text)\n",
        "    label = torch.tensor( label , dtype=torch.float32)\n",
        "    #print(w2v_data.shape)\n",
        "    #print(w2v_data.dtype)\n",
        "    return w2v_data, label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting, preparing and loading dataset"
      ],
      "metadata": {
        "id": "_LlD9a-jALWT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5wYdDESadi1"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_helper = Datasethelper(train_df)\n",
        "test_helper = Datasethelper(test_df)\n",
        "\n",
        "\n",
        "train_dloader = DataLoader(train_helper, batch_size = 12 , shuffle = True)\n",
        "test_dloader = DataLoader(test_helper, batch_size = 12 , shuffle = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_uH2ZA6ahiW",
        "outputId": "7d29fdf9-3622-424a-c1e9-67bc3164c0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 10, 300])\n",
            "torch.Size([12])\n"
          ]
        }
      ],
      "source": [
        "for x,y in train_dloader:\n",
        "  break\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining NN model"
      ],
      "metadata": {
        "id": "BTBVtY2nAWo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edyuG5XEajqr"
      },
      "outputs": [],
      "source": [
        "class NN4(nn.Module):\n",
        "    def __init__(self, input_dim = 300, hidden_dim1 = 128, hidden_dim2 = 64):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = 1\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X=torch.mean(X,1)\n",
        "        X.requires_grad=True\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "        X = self.sigmoid(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing model, optimizer and criterion"
      ],
      "metadata": {
        "id": "uo3GAzyaAaRB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXjQINtuasJi"
      },
      "outputs": [],
      "source": [
        "NNmodel = NN4()\n",
        "criterion=nn.BCELoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(NNmodel.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "YN91LKKTAgkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  overall_accuracy=0\n",
        "  for x,y in train_dloader:\n",
        "    #print(\"from tloader x :\" + str(x.shape))\n",
        "    #print(\"from tloader y :\" + str(y.shape))\n",
        "    predicted_y=NNmodel(x)\n",
        "    #print(\"NNmodel out y_pred:\" +str(predicted_y.shape))\n",
        "    batch_size=x.shape[0]\n",
        "    y=y.view(batch_size,1)\n",
        "    #print(\"tloader y from view:\"+ str(y.shape))\n",
        "    loss=criterion(predicted_y,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    y_true=y.detach().numpy()\n",
        "    #y_pred=predicted_y.detach().numpy() >0.5\n",
        "    y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "    accuracy= accuracy_score(y_true,y_pred)\n",
        "    overall_accuracy +=accuracy*batch_size\n",
        "\n",
        "\n",
        "  print(f'Epoch: {epoch} --> Accuracy {overall_accuracy/len(train_helper)}')\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "EtSYGS8UYD2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8102da89-4e62-4a22-83d6-0cb84dbff0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --> Accuracy 0.8657534246575342\n",
            "Epoch: 1 --> Accuracy 0.8561643835616438\n",
            "Epoch: 2 --> Accuracy 0.8671232876712329\n",
            "Epoch: 3 --> Accuracy 0.863013698630137\n",
            "Epoch: 4 --> Accuracy 0.8643835616438356\n",
            "Epoch: 5 --> Accuracy 0.863013698630137\n",
            "Epoch: 6 --> Accuracy 0.8684931506849315\n",
            "Epoch: 7 --> Accuracy 0.8753424657534247\n",
            "Epoch: 8 --> Accuracy 0.8753424657534247\n",
            "Epoch: 9 --> Accuracy 0.873972602739726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "1inMZMr_DMg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "overall_accuracy = 0\n",
        "for x, y in test_dloader:\n",
        "    predicted_y = NNmodel(x)\n",
        "    batch_size = x.shape[0]\n",
        "    y = y.view(batch_size, 1)\n",
        "    y_true = y.detach().numpy()\n",
        "    y_pred = predicted_y.detach().numpy() > 0.5\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    overall_accuracy += accuracy * batch_size\n",
        "test_accuracy = overall_accuracy / len(test_helper)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W84OWsBCChQ6",
        "outputId": "c0e8ad65-96d9-4257-d4ea-cee4cb72f7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8469945355191257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing per epoch"
      ],
      "metadata": {
        "id": "wK9ij9T9Aq1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "for epoch in range(10):\n",
        "    overall_accuracy = 0\n",
        "    for x, y in test_dloader:\n",
        "        predicted_y = NNmodel(x)\n",
        "        batch_size = x.shape[0]\n",
        "        y = y.view(batch_size, 1)\n",
        "        y_true = y.detach().numpy()\n",
        "        y_pred = predicted_y.detach().numpy() > 0.5\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        overall_accuracy += accuracy * batch_size\n",
        "    test_accuracy = overall_accuracy / len(test_helper)\n",
        "    print(f'Test Epoch: {epoch} --> Accuracy {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC1Fq1qir3bP",
        "outputId": "ca6939ec-4124-4e09-c4eb-e88ed47e1576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Epoch: 0 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 1 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 2 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 3 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 4 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 5 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 6 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 7 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 8 --> Accuracy 0.8360655737704918\n",
            "Test Epoch: 9 --> Accuracy 0.8360655737704918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN"
      ],
      "metadata": {
        "id": "m2qIGeHhUd10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rnn1- problem : output dim changes in the end"
      ],
      "metadata": {
        "id": "XK8GCjJ4FbSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim=300, hidden_dim=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        _, hn = self.rnn(X)\n",
        "        return hn"
      ],
      "metadata": {
        "id": "UrmYe2oXUgI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rnn2"
      ],
      "metadata": {
        "id": "rFoLBXfcFhNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN2(nn.Module):\n",
        "    def __init__(self, input_dim=300, hidden_dim=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        batch_size = X.size(0)  # Get the batch size\n",
        "        _, hn = self.rnn(X)\n",
        "        hn = hn.permute(1, 0, 2).contiguous()  # Transpose and reshape to [batch_size, 1, hidden_dim]\n",
        "        return hn"
      ],
      "metadata": {
        "id": "ly5kLkxC7MML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing hn to LL via NN5- problem y and pred_y Dim don't match"
      ],
      "metadata": {
        "id": "ub6HaSzYFlGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN5(nn.Module):\n",
        "    def __init__(self, input_dim = 64, hidden_dim1 = 128, hidden_dim2 = 64):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = 1\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        batch_size = X.shape[0]\n",
        "        X=torch.mean(X,1)\n",
        "        #X.requires_grad=True\n",
        "        X = torch.tensor(X, requires_grad=True)\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "        #X = self.sigmoid(X)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "EoYTCF1hXu7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing hn to LL via NN6"
      ],
      "metadata": {
        "id": "M-BJGGMxFyg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN6(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim1=128, hidden_dim2=64, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = output_dim\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        batch_size = X.shape[0]\n",
        "        X = torch.mean(X, 1)\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "        X = self.sigmoid(X)\n",
        "\n",
        "        #return X\n",
        "        return X.view(batch_size, self.output_dim)\n"
      ],
      "metadata": {
        "id": "EIq02OEtnTM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initializing the models, setting optimer and criterion"
      ],
      "metadata": {
        "id": "WEFbNSUYH7n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = RNN2()\n",
        "nn_model2 = NN6()\n",
        "\n",
        "criterion2 = nn.BCELoss(reduction='mean')\n",
        "optimizer2 = torch.optim.Adam(nn_model2.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "5c3v_Id9VF5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking shapes of the outputs from the models"
      ],
      "metadata": {
        "id": "JP4TR41GI3lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t,p in train_dloader:\n",
        "  rnnout = rnn_model(t)\n",
        "  print(rnnout.shape)\n",
        "  g = nn_model2(rnnout)\n",
        "  print(g.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nL0pOHmIVnc",
        "outputId": "554b659c-00fc-4eea-905f-eff85210549f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([12, 1, 64])\n",
            "torch.Size([12, 1])\n",
            "torch.Size([10, 1, 64])\n",
            "torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "NiqS-ryLIEdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    overall_accuracy = 0\n",
        "    for x, y in train_dloader:\n",
        "        #print(f'from tloader y: {y.shape}')\n",
        "        rnn_output = rnn_model(x)\n",
        "        #print(f'rnn out:  {rnn_output.shape}')\n",
        "        predicted_y = nn_model2(rnn_output)\n",
        "        #print(f'pred-y from NN6: {predicted_y.shape}')\n",
        "        batch_size = x.shape[0]\n",
        "        #predicted_y = predicted_y.squeeze(1).t()\n",
        "        #print(f'pred-y from squeeze: {predicted_y.shape}')\n",
        "        y = y.view(batch_size, 1)\n",
        "        #print(f'final y from view: {y.shape}')\n",
        "        loss = criterion2(predicted_y, y)\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        y_true = y.detach().numpy()\n",
        "        y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        overall_accuracy += accuracy * batch_size\n",
        "\n",
        "    print(f'Epoch: {epoch} --> Accuracy {overall_accuracy/len(train_helper)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vf48KyI4pa4",
        "outputId": "feb52e15-595e-4107-8fdd-287cb5b76bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --> Accuracy 0.5150684931506849\n",
            "Epoch: 1 --> Accuracy 0.5315068493150685\n",
            "Epoch: 2 --> Accuracy 0.5315068493150685\n",
            "Epoch: 3 --> Accuracy 0.5191780821917809\n",
            "Epoch: 4 --> Accuracy 0.5246575342465754\n",
            "Epoch: 5 --> Accuracy 0.5342465753424658\n",
            "Epoch: 6 --> Accuracy 0.5589041095890411\n",
            "Epoch: 7 --> Accuracy 0.5260273972602739\n",
            "Epoch: 8 --> Accuracy 0.5328767123287671\n",
            "Epoch: 9 --> Accuracy 0.5383561643835616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "WS_H4bNTIH3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "overall_accuracy = 0\n",
        "for x, y in test_dloader:\n",
        "    rnn_output = rnn_model(x)\n",
        "    predicted_y = nn_model2(rnn_output)\n",
        "    batch_size = x.shape[0]\n",
        "    y = y.view(batch_size, 1)\n",
        "    y_true = y.detach().numpy()\n",
        "    y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    overall_accuracy += accuracy * batch_size\n",
        "test_accuracy = overall_accuracy / len(test_helper)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "w6ul17pZW-yY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9942c44b-400e-4fe1-ca55-d27abe1e3ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5628415300546448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "vxLtSncLIOcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim=300, hidden_dim=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        _, (hn, _) = self.lstm(X)\n",
        "        hn = hn.permute(1, 0, 2).contiguous()\n",
        "        return hn.view(X.size(0), 1, self.hidden_dim)"
      ],
      "metadata": {
        "id": "rkRsCeXUJ0Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN7(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim1=128, hidden_dim2=64, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = output_dim\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        batch_size = X.shape[0]\n",
        "        X = torch.mean(X, 1)\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "        X = self.sigmoid(X)\n",
        "\n",
        "        #return X\n",
        "        return X.view(batch_size, self.output_dim)"
      ],
      "metadata": {
        "id": "oojDIl24KQH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = LSTM()\n",
        "nn_model3 = NN7()\n",
        "\n",
        "criterion2 = nn.BCELoss(reduction='mean')\n",
        "optimizer2 = torch.optim.Adam(nn_model3.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "11sBUkCaKbf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    overall_accuracy = 0\n",
        "    for x, y in train_dloader:\n",
        "        #print(f'from tloader y: {y.shape}')\n",
        "        lstm_output = lstm_model(x)\n",
        "        #print(f'rnn out:  {rnn_output.shape}')\n",
        "        predicted_y = nn_model3(lstm_output)\n",
        "        #print(f'pred-y from NN6: {predicted_y.shape}')\n",
        "        batch_size = x.shape[0]\n",
        "        #predicted_y = predicted_y.squeeze(1).t()\n",
        "        #print(f'pred-y from squeeze: {predicted_y.shape}')\n",
        "        y = y.view(batch_size, 1)\n",
        "        #print(f'final y from view: {y.shape}')\n",
        "        loss = criterion2(predicted_y, y)\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        y_true = y.detach().numpy()\n",
        "        y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        overall_accuracy += accuracy * batch_size\n",
        "\n",
        "    print(f'Epoch: {epoch} --> Accuracy {overall_accuracy/len(train_helper)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhMVF2LeKcwK",
        "outputId": "822bcd35-4a9a-4ce0-f92d-b3b06a90aa2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --> Accuracy 0.4931506849315068\n",
            "Epoch: 1 --> Accuracy 0.4986301369863014\n",
            "Epoch: 2 --> Accuracy 0.46164383561643835\n",
            "Epoch: 3 --> Accuracy 0.5287671232876713\n",
            "Epoch: 4 --> Accuracy 0.4780821917808219\n",
            "Epoch: 5 --> Accuracy 0.5205479452054794\n",
            "Epoch: 6 --> Accuracy 0.49726027397260275\n",
            "Epoch: 7 --> Accuracy 0.5027397260273972\n",
            "Epoch: 8 --> Accuracy 0.5027397260273972\n",
            "Epoch: 9 --> Accuracy 0.5123287671232877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "overall_accuracy = 0\n",
        "for x, y in test_dloader:\n",
        "    lstm_output = lstm_model(x)\n",
        "    predicted_y = nn_model3(lstm_output)\n",
        "    batch_size = x.shape[0]\n",
        "    y = y.view(batch_size, 1)\n",
        "    y_true = y.detach().numpy()\n",
        "    y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    overall_accuracy += accuracy * batch_size\n",
        "test_accuracy = overall_accuracy / len(test_helper)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "070kZulHOV6p",
        "outputId": "adca6f1f-fd37-401a-875e-9a0f42f2da67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5573770491803278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU"
      ],
      "metadata": {
        "id": "bWS-OrZtPdZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim=300, hidden_dim=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        _, hn = self.gru(X)\n",
        "        hn = hn.permute(1, 0, 2).contiguous()\n",
        "        return hn.view(X.size(0), 1, self.hidden_dim)"
      ],
      "metadata": {
        "id": "0FViABlmQJnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN8(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim1=128, hidden_dim2=64, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = output_dim\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        batch_size = X.shape[0]\n",
        "        X = torch.mean(X, 1)\n",
        "        #X.requires_grad=True\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "        X = self.sigmoid(X)\n",
        "\n",
        "        #return X.view(batch_size)\n",
        "        #return X\n",
        "        return X.view(batch_size, self.output_dim)"
      ],
      "metadata": {
        "id": "FcG-QYsdQM23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = GRU()\n",
        "nn_model5 = NN8()\n",
        "\n",
        "criterion = nn.BCELoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(nn_model3.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "CoNrnGkfQZZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    overall_accuracy = 0\n",
        "    for x, y in train_dloader:\n",
        "        #print(f'from tloader x: {x.shape}')\n",
        "        #print(f'from tloader y: {y.shape}')\n",
        "        gru_output = gru_model(x)\n",
        "        #print(f'gru out:  {gru_output.shape}')\n",
        "        predicted_y = nn_model5(gru_output)\n",
        "        #print(f'pred-y from NN8: {predicted_y.shape}')\n",
        "        batch_size = x.shape[0]\n",
        "        #predicted_y = predicted_y.squeeze(1).t()\n",
        "        #print(f'pred-y from squeeze: {predicted_y.shape}')\n",
        "        y = y.view(batch_size, 1)\n",
        "        #print(f'final y from view: {y.shape}')\n",
        "        loss = criterion(predicted_y, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        y_true = y.detach().numpy()\n",
        "        y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        overall_accuracy += accuracy * batch_size\n",
        "\n",
        "    print(f'Epoch: {epoch} --> Accuracy {overall_accuracy/len(train_helper)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpg_9VBQeCg",
        "outputId": "df27f37e-35a4-4799-ad4d-7898d6808028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --> Accuracy 0.5095890410958904\n",
            "Epoch: 1 --> Accuracy 0.5095890410958904\n",
            "Epoch: 2 --> Accuracy 0.5095890410958904\n",
            "Epoch: 3 --> Accuracy 0.5095890410958904\n",
            "Epoch: 4 --> Accuracy 0.5095890410958904\n",
            "Epoch: 5 --> Accuracy 0.5095890410958904\n",
            "Epoch: 6 --> Accuracy 0.5095890410958904\n",
            "Epoch: 7 --> Accuracy 0.5095890410958904\n",
            "Epoch: 8 --> Accuracy 0.5095890410958904\n",
            "Epoch: 9 --> Accuracy 0.5095890410958904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "overall_accuracy = 0\n",
        "for x, y in test_dloader:\n",
        "    gru_output = gru_model(x)\n",
        "    predicted_y = nn_model5(gru_output)\n",
        "    batch_size = x.shape[0]\n",
        "    y = y.view(batch_size, 1)\n",
        "    y_true = y.detach().numpy()\n",
        "    y_pred = (predicted_y.detach().numpy() > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    overall_accuracy += accuracy * batch_size\n",
        "test_accuracy = overall_accuracy / len(test_helper)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-lLOFbgZyX2",
        "outputId": "f62f27a8-d634-4736-d581-22b5659d0352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5573770491803278\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}