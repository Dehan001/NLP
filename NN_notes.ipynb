{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G4nAMn9UpxW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgCDLuCL5vQF"
      },
      "source": [
        "#Neural Network Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFXGGdL4U8Mw",
        "outputId": "e9b8a0d8-31e1-4ca9-e161-7a662e6005ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.7\n"
          ]
        }
      ],
      "source": [
        "inputs = [1.2, 5.1, 2.1]\n",
        "weights = [3.1, 2.1, 8.7]\n",
        "bias = 3.0\n",
        "\n",
        "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWE2ayl256RD"
      },
      "source": [
        "#Mathematical calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz9g2QMzVCbL",
        "outputId": "6cec5ec0-e91e-4dc6-e8f8-2f69be6ceb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.8, 1.21, 2.385]\n"
          ]
        }
      ],
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "\n",
        "weights1 = [0.2, 0.8, -0.5, 1.0]\n",
        "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
        "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
        "\n",
        "bias1 = 2.0\n",
        "bias2 = 3.0\n",
        "bias3 = 0.5\n",
        "\n",
        "output = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]*weights1[3] + bias1,\n",
        "          inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]*weights2[3] + bias2,\n",
        "          inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]*weights3[3] + bias3]\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGCQEIOh6KHk"
      },
      "source": [
        "#By numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJrMWOz_XJ3u",
        "outputId": "ed9219bf-a406-41fb-c95b-520210ffdc2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.8   1.21  2.385]\n"
          ]
        }
      ],
      "source": [
        "inputs = [1.0, 2.0, 3.0, 2.5]\n",
        "weights = [[0.2, 0.8, -0.5, 1.0],\n",
        "           [0.5, -0.91, 0.26, -0.5],\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2.0, 3.0, 0.5]\n",
        "\n",
        "output = np.dot(weights, inputs) + biases\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j25BLntk6S_B"
      },
      "source": [
        "#Defining 2 layer NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o883_0HTXQwA",
        "outputId": "ae87a747-9833-46f4-fb94-c72875a065c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.148296   -0.08397602]\n",
            " [ 0.14100315 -0.01340469]\n",
            " [ 0.20124979 -0.07290616]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "X = [[1, 2, 3, 2.5],\n",
        "     [2.0, 5.0, -1.0, 2.0],\n",
        "     [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "layer1 = Layer_Dense(4,5)\n",
        "layer2 = Layer_Dense(5,2)\n",
        "\n",
        "layer1.forward(X)\n",
        "layer2.forward(layer1.output)\n",
        "print(layer2.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5UiJPdN6hZ8"
      },
      "source": [
        "#Softmax calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4cQLaeXucF",
        "outputId": "ae17b8d8-4f82-49ce-be72-a00ca0f3e3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35667494393873245\n",
            "0.35667494393873245\n",
            "0.6931471805599453\n"
          ]
        }
      ],
      "source": [
        "softmax_output = [0.7, 0.1, 0.2]\n",
        "target_output = [1, 0, 0]\n",
        "\n",
        "loss = -(math.log(softmax_output[0]) * target_output[0] +\n",
        "         math.log(softmax_output[1]) * target_output[1] +\n",
        "         math.log(softmax_output[2]) * target_output[2])\n",
        "\n",
        "print(loss)\n",
        "\n",
        "print(-math.log(0.7))\n",
        "print(-math.log(0.5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8wDIhUQ6mvG"
      },
      "source": [
        "#Neural Network---- 300 dim vector, output 1 value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhOIATLh5jpW",
        "outputId": "44b6a83b-dff9-461a-b6e0-f568beb9d8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.76405235  0.40015721  0.97873798 ...  0.58295368 -0.39944903\n",
            "   0.37005589]\n",
            " [-1.30652685  1.65813068 -0.11816405 ... -0.21673147 -0.9301565\n",
            "  -0.17858909]\n",
            " [-1.55042935  0.41731882 -0.94436849 ... -1.5415874   2.59442459\n",
            "  -0.40403229]\n",
            " [-1.46173269 -0.68343977  0.3675449  ... -0.59377745 -2.01188032\n",
            "   0.58970361]\n",
            " [-0.89636972 -1.96273201  1.58482053 ... -0.24679356 -1.07934317\n",
            "  -0.11422555]]\n",
            "1.8540740851287625\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "x = np.random.randn(5, 300)\n",
        "print(x)\n",
        "\n",
        "\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "    def sig(self, x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = self.sig(np.dot(inputs, self.weights) + self.biases)\n",
        "\n",
        "\n",
        "layer1 = Layer_Dense(300,128)\n",
        "layer2 = Layer_Dense(128,64)\n",
        "layer3 = Layer_Dense(64,1)\n",
        "\n",
        "layer1.forward(x)\n",
        "layer2.forward(layer1.output)\n",
        "layer3.forward(layer2.output)\n",
        "\n",
        "print(np.sum(layer3.output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiMeFFhc6Nxt"
      },
      "source": [
        "====================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_NmXeB37G8E"
      },
      "source": [
        "#NN Produces a column vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDCg9in86NBA",
        "outputId": "0a833748-6a4c-4f58-c60b-c5b45c3d2664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.87631142]\n",
            " [-2.68543646]\n",
            " [-1.76685814]\n",
            " [-6.79381638]\n",
            " [-2.60843937]]\n"
          ]
        }
      ],
      "source": [
        "class NN:\n",
        "    def __init__(self):\n",
        "        self.input_size = 300\n",
        "        self.hidden_size1 = 128\n",
        "        self.hidden_size2 = 64\n",
        "        self.output_size = 1\n",
        "        self.weights1 = np.random.randn(self.input_size, self.hidden_size1)\n",
        "        self.weights2 = np.random.randn(self.hidden_size1, self.hidden_size2)\n",
        "        self.weights3 = np.random.randn(self.hidden_size2, self.output_size)\n",
        "\n",
        "    def sig(self,x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h1 = self.sig(np.dot(x, self.weights1))\n",
        "        h2 = self.sig(np.dot(h1, self.weights2))\n",
        "        output = np.dot(h2, self.weights3)\n",
        "        return output\n",
        "\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "nn = NN()\n",
        "x = np.random.randn(5, 300)\n",
        "output = nn.forward(x)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiX-7KD77MH_"
      },
      "source": [
        "#Taking sum of column vector to get one numerical value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hmlo0ox_FAc",
        "outputId": "ca421b2b-a7b1-4908-b8fe-ca96e6abc84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.68850505 -0.55654582 -1.99202607 ...  0.51513974 -0.00986603\n",
            "   0.46955072]\n",
            " [-1.95513697  0.17081812 -1.20061398 ...  1.51421791 -1.10782602\n",
            "   0.37952939]\n",
            " [ 1.7709085   0.49840167 -0.24363041 ...  0.89501937 -0.24989759\n",
            "   0.02544529]\n",
            " [ 0.76790934  0.39772379 -1.28605947 ... -0.002438    1.16372727\n",
            "  -1.94810007]\n",
            " [ 1.46031038  1.55500125 -1.22550287 ...  0.5406267  -0.11519955\n",
            "   0.88387229]]\n",
            "1.3076315991828378\n"
          ]
        }
      ],
      "source": [
        "class NN2:\n",
        "    def __init__(self):\n",
        "        self.input_dim = 300\n",
        "        self.hidden_dim1 = 128\n",
        "        self.hidden_dim2 = 64\n",
        "        self.output_dim = 1\n",
        "        self.W1 = np.random.randn(self.hidden_dim1, self.input_dim)\n",
        "        self.b1 = np.random.randn(self.hidden_dim1)\n",
        "        self.W2 = np.random.randn(self.hidden_dim2, self.hidden_dim1)\n",
        "        self.b2 = np.random.randn(self.hidden_dim2)\n",
        "        self.W3 = np.random.randn(self.output_dim, self.hidden_dim2)\n",
        "        self.b3 = np.random.randn(self.output_dim)\n",
        "\n",
        "    def sig(self,x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, X):\n",
        "        L1 = self.sig(np.dot(self.W1, X.T) + self.b1.reshape(-1, 1))\n",
        "        L2 = self.sig(np.dot(self.W2, L1) + self.b2.reshape(-1, 1))\n",
        "        L3 = self.sig(np.dot(self.W3, L2) + self.b3.reshape(-1, 1))\n",
        "        output = np.sum(L3)\n",
        "        return output\n",
        "\n",
        "\n",
        "nn2 = NN2()\n",
        "x = np.random.randn(5, 300)\n",
        "print(x)\n",
        "output = nn2.forward(x)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lnrSU6aFjQy"
      },
      "source": [
        "========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU-2c4eE7VmF"
      },
      "source": [
        "#Input vectors are w2v representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kye0hU19FktY",
        "outputId": "3835e707-29a0-4ee6-f5dc-fe0fe251d6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1661.5/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63MHo6-8HhBw"
      },
      "outputs": [],
      "source": [
        "class NN3:\n",
        "    def __init__(self):\n",
        "        self.input_dim = 300\n",
        "        self.hidden_dim1 = 128\n",
        "        self.hidden_dim2 = 64\n",
        "        self.output_dim = 1\n",
        "        self.W1 = np.random.randn(self.hidden_dim1, self.input_dim)\n",
        "        self.b1 = np.random.randn(self.hidden_dim1)\n",
        "        self.W2 = np.random.randn(self.hidden_dim2, self.hidden_dim1)\n",
        "        self.b2 = np.random.randn(self.hidden_dim2)\n",
        "        self.W3 = np.random.randn(self.output_dim, self.hidden_dim2)\n",
        "        self.b3 = np.random.randn(self.output_dim)\n",
        "\n",
        "    def sig(self,x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, X):\n",
        "        L1 = self.sig(np.dot(self.W1, X.T) + self.b1.reshape(-1, 1))\n",
        "        L2 = self.sig(np.dot(self.W2, L1) + self.b2.reshape(-1, 1))\n",
        "        L3 = self.sig(np.dot(self.W3, L2) + self.b3.reshape(-1, 1))\n",
        "        output = self.sig(np.sum(L3))\n",
        "        return output\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b9DrnMALIVB",
        "outputId": "33eef5ec-2d71-45d1-e321-28650e62c28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.07910156 -0.0050354   0.11181641 ... -0.0067749   0.04272461\n",
            "  -0.10351562]\n",
            " [-0.16699219 -0.06640625  0.05737305 ... -0.05419922  0.1171875\n",
            "   0.08398438]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.0123291   0.20410156 -0.28515625 ...  0.4921875  -0.27539062\n",
            "   0.05615234]]\n",
            "0.9806846636253227\n"
          ]
        }
      ],
      "source": [
        "nn3 = NN3()\n",
        "sentence = \"I am a cat\"\n",
        "tokens = sentence.split()\n",
        "vectors = []\n",
        "for token in tokens:\n",
        "    vec = w2v_model[token] if token in w2v_model else np.zeros(300)\n",
        "    vectors.append(vec)\n",
        "\n",
        "\n",
        "vectors = np.array(vectors)\n",
        "print(vectors)\n",
        "\n",
        "output = nn3.forward(vectors)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQLl0IWGpsk"
      },
      "source": [
        "#NN in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGvy-VixMnf8",
        "outputId": "107d309e-eaef-4b73-a037-fd85f586aa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_hLbspOG1eB"
      },
      "source": [
        "# Text preprocessing module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o27m3XUYSwFw"
      },
      "outputs": [],
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.punctuations = set(string.punctuation)\n",
        "\n",
        "    def process_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        text = ''.join(char for char in text if char not in self.punctuations)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        text = ' '.join(tokens)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def process_column(self, df, column_name):\n",
        "        df[column_name] = df[column_name].apply(self.process_text)\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyOGor3HG-uo"
      },
      "source": [
        "#Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VwTCX6mTDd7",
        "outputId": "bfca5bb4-cf2c-4ea3-f2d9-beba19ea4004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0                           Wow... Loved this place.      1\n",
            "1                                 Crust is not good.      0\n",
            "2          Not tasty and the texture was just nasty.      0\n",
            "3  Stopped by during the late May bank holiday of...      1\n",
            "4  The selection on the menu was great and so wer...      1\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('restuarents.csv', encoding='ISO-8859-1')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQWe3vPEHD8i"
      },
      "source": [
        "#Applying preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kkRWkJRTHZf",
        "outputId": "0210746d-0c64-4942-f6da-6cbbd30edb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0                                    wow loved place      1\n",
            "1                                         crust good      0\n",
            "2                                tasty texture nasty      0\n",
            "3  stopped late may bank holiday rick steve recom...      1\n",
            "4                        selection menu great prices      1\n"
          ]
        }
      ],
      "source": [
        "preprocessor = TextPreprocessor()\n",
        "df = preprocessor.process_column(data, 'text')\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#w2v function"
      ],
      "metadata": {
        "id": "_vEN9_Gk1PM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v(sentence):\n",
        "    tokens = sentence.split()\n",
        "    vec = []\n",
        "    for token in tokens:\n",
        "        if token in w2v_model:\n",
        "            vec.append(w2v_model[token])\n",
        "        else:\n",
        "            vec.append(np.zeros(300))\n",
        "\n",
        "    #vec = sum(vec)/len(vec)\n",
        "    return torch.tensor(vec)"
      ],
      "metadata": {
        "id": "4GGcqp4CIPIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = w2v(\"I am a student\")\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF8QfCuzItJ5",
        "outputId": "447a94d5-cedb-4920-d8e4-9630be6b06bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset's child class for preparing data + Tensor conversion"
      ],
      "metadata": {
        "id": "9SKwcO7U1W94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAv2ULCkVcB-"
      },
      "outputs": [],
      "source": [
        "class Datasethelper(Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.data = df['text'].values\n",
        "    self.labels = df['label'].values\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    text = self.data[index]\n",
        "    label = self.labels[index]\n",
        "    w2v_data = w2v(text)\n",
        "    label = torch.tensor( label , dtype=torch.float32)\n",
        "    print(w2v_data.shape)\n",
        "    return w2v_data, label\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting dataset + dataloader"
      ],
      "metadata": {
        "id": "qSQ3FB9M2gHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YBqf-38ducm"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_helper = Datasethelper(train_df)\n",
        "test_helper = Datasethelper(test_df)\n",
        "\n",
        "\n",
        "train_dloader = DataLoader(train_helper, batch_size = 10 , shuffle = True)\n",
        "test_dloader = DataLoader(test_helper, batch_size = 10 , shuffle = False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch,label in train_dloader:\n",
        "  break\n",
        "print(batch.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "8Ih_ok0IJf7Z",
        "outputId": "e3e5b327-6287-42c3-bbd2-2d1e8041bd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 300])\n",
            "torch.Size([3, 300])\n",
            "torch.Size([2, 300])\n",
            "torch.Size([7, 300])\n",
            "torch.Size([10, 300])\n",
            "torch.Size([4, 300])\n",
            "torch.Size([2, 300])\n",
            "torch.Size([6, 300])\n",
            "torch.Size([8, 300])\n",
            "torch.Size([7, 300])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-2a8afba44313>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 300] at entry 0 and [2, 300] at entry 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZZYyf3Hftdd"
      },
      "outputs": [],
      "source": [
        "class NN4(nn.Module):\n",
        "    def __init__(self, input_dim = 300, hidden_dim1 = 128, hidden_dim2 = 64):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.output_dim = 1\n",
        "        self.LL1 = nn.Linear(self.input_dim, self.hidden_dim1)\n",
        "        self.LL2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.FL = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.mean(axis=1)\n",
        "        X = self.LL1(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.LL2(X)\n",
        "        X = self.sigmoid(X)\n",
        "        X = self.FL(X)\n",
        "\n",
        "        return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL_5A_oFiV1q"
      },
      "outputs": [],
      "source": [
        "NNmodel = NN4()\n",
        "crit = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(NNmodel.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def accuracy(y_pred, y_acc):\n",
        "    #y_pred = y_pred.argmax(dim=1)\n",
        "    #correct = (y_pred == y_acc).sum().item()\n",
        "    #total = y_acc.size(0)\n",
        "    #return correct / total"
      ],
      "metadata": {
        "id": "fQ5hKVqm84Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RAXHc_72ihhS",
        "outputId": "aeec2d5f-6538-4c02-9c9b-75fe01d35c53"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-fe7db7a6a521>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-55ed84eb8634>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLL1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x10 and 300x128)"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "  for x, y in train_dloader:\n",
        "    predicted_y = NNmodel(x)\n",
        "    loss = crit(predicted_y, y)\n",
        "    loss.backward()\n",
        "    optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = accuracy(predicted_y.detach().numpy, y.detach().numpy)\n",
        "    print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}